{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0831bb3-9294-4b7d-a835-848953b9c4f8",
   "metadata": {},
   "source": [
    "### Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7ab4c6-9751-4faf-ad65-12e8b1b8e91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn\n",
    "!pip install scipy\n",
    "!pip install scikit-learn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy.stats import pointbiserialr\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac04b3e-0c91-4a2b-b04f-ffdddbad4580",
   "metadata": {},
   "source": [
    "### Citirea setului de date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c9670a-37e5-4e54-ad2c-c3720419467d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Citirea setului de date\n",
    "df = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303a99f6-b81f-4c94-ac18-b7fff88cc5b1",
   "metadata": {},
   "source": [
    "### Filtrarea datelor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3e8bcb-40b4-429b-bfc7-4b4c671b1390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminam din dataset NaN si +- Inifity\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e343c0-5aeb-4769-a143-b54d1b9e0b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inlocuiesc NaN si +- Infinity cu mediana pe coloane pentru\n",
    "#df = df.replace([np.inf, -np.inf], np.nan)\n",
    "#df = df.apply(lambda x: x.fillna(x.median()), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72289c18-a63e-4ddf-bb09-3a5ab314ae66",
   "metadata": {},
   "source": [
    "# 3.1. Explorarea Datelor (Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd147483-f34d-4af4-bb90-d234eb113d5c",
   "metadata": {},
   "source": [
    "## 1. Analiza Echilibrului de Clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22718d3-4280-437a-9c57-855c2c4f2eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificarea echilibrului claselor\n",
    "sns.countplot(x='Revenue', data=df)\n",
    "plt.title('Distribuția claselor pentru Revenue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a88e33-68d6-4ace-a80f-1f3578988aab",
   "metadata": {},
   "source": [
    "## 2. Vizualizarea Atributelor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41822ed-4e7f-42d3-983d-ec7c0b051e19",
   "metadata": {},
   "source": [
    "### 2.A Atribute Numerice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392cf0cd-5d7e-4202-8db4-72ec6f8c7980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificarea atributelor numerice\n",
    "numeric_attributes = df.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "# Vizualizare distribuție pentru atribute numerice\n",
    "for attribute in numeric_attributes:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.histplot(df[attribute], bins=30, kde=True)\n",
    "    plt.title(f'Distribuția atributului {attribute}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1d072f-38a0-4277-89c1-eee5530ca4c2",
   "metadata": {},
   "source": [
    "### 2.A Atribute Categorice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cac654-ecbf-4a9c-aa0b-57f5a002cb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificarea atributelor categorice\n",
    "categorical_attributes = df.select_dtypes(exclude=np.number).columns.tolist()\n",
    "\n",
    "# Vizualizare distribuție pentru atribute categorice\n",
    "for attribute in categorical_attributes:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.countplot(x=attribute, data=df, hue='Revenue')\n",
    "    plt.title(f'Distribuția atributului {attribute} în funcție de Revenue')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55bc6b1-0ee8-4794-ac30-dea77f4f417e",
   "metadata": {},
   "source": [
    "## 3. Analiza Gradului de Corelare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110726fc-a162-4148-b1b8-ba30ed2d26ce",
   "metadata": {},
   "source": [
    "### 3.A Atribute Numerice cu Coeficientul de Point-Biserial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b0fb33-a6bd-471c-8e2b-d1d8ae63c6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_results_numeric = []\n",
    "\n",
    "for attribute in numeric_attributes:\n",
    "    if attribute != 'Revenue':\n",
    "        correlation, p_value = pointbiserialr(df[attribute], df['Revenue'])\n",
    "        correlation_results_numeric.append({'Attribute': attribute, 'Correlation': correlation, 'P-Value': p_value})\n",
    "\n",
    "# Tabelul cu rezultate\n",
    "correlation_df_numeric = pd.DataFrame(correlation_results_numeric)\n",
    "print(correlation_df_numeric)\n",
    "print('\\n')\n",
    "\n",
    "# Vizualizare pentru atributele cu p-value <= 0.05\n",
    "significant_numeric_attributes = correlation_df_numeric[correlation_df_numeric['P-Value'] <= 0.05]\n",
    "plt.figure(figsize=(12, 6))\n",
    "barplot = sns.barplot(x='Attribute', y='Correlation', data=significant_numeric_attributes)\n",
    "plt.title('Coeficient de Point-Biserial pentru Atributele Numerice')\n",
    "\n",
    "# Rotirea etichetelor pe axa X pentru a face vizualizarea mai lizibilă\n",
    "X_fields = significant_numeric_attributes['Attribute'].tolist()\n",
    "barplot.set_xticks(range(len(X_fields)))\n",
    "barplot.set_xticklabels(X_fields, rotation=45, horizontalalignment='right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f407e760-7d69-46fa-8f77-113f35ac3b51",
   "metadata": {},
   "source": [
    "### 3.B Atribute Categorice cu Testul Chi-squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bc819a-dd5a-4b06-beff-27250857b643",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_results_categorical = []\n",
    "\n",
    "for attribute in categorical_attributes:\n",
    "    contingency_table = pd.crosstab(df[attribute], df['Revenue'])\n",
    "    chi2, p_value, _, _ = chi2_contingency(contingency_table)\n",
    "    correlation_results_categorical.append({'Attribute': attribute, 'Chi-squared': chi2, 'P-Value': p_value})\n",
    "\n",
    "# Tabelul cu rezultate\n",
    "correlation_df_categorical = pd.DataFrame(correlation_results_categorical)\n",
    "print(correlation_df_categorical)\n",
    "print('\\n')\n",
    "\n",
    "# Vizualizare pentru atributele cu p-value <= 0.05\n",
    "significant_categorical_attributes = correlation_df_categorical[correlation_df_categorical['P-Value'] <= 0.05]\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Attribute', y='Chi-squared', data=significant_categorical_attributes)\n",
    "plt.title('Statistica Chi-squared pentru Atributele Categorice')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089dfbc1-823f-40e5-827a-b9ff7f40b5d4",
   "metadata": {},
   "source": [
    "# 3.2. Antrenarea și Evaluarea Algoritmilor de Predicție"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12360a73-76ff-4f72-a691-fb9e5d685ab7",
   "metadata": {},
   "source": [
    "## 3.2.1. Regresie Logistică"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f54fc8b-8053-448c-8644-43ce2542e849",
   "metadata": {},
   "source": [
    "### 1. Implementare manuală"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9878dadd-3e2b-4f85-a024-2ba6318b5fea",
   "metadata": {},
   "source": [
    "#### Regresia Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de53e17-5b11-4c9f-b52b-45c9cfd89532",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X, T, train=.8, shuffle=True):\n",
    "    N = X.shape[0]\n",
    "    N_train = int(round(N * train))\n",
    "    N_test = N - N_train\n",
    "\n",
    "    X_train, X_test = X[:N_train, :], X[N_train:, :]\n",
    "    T_train, T_test = T[:N_train], T[N_train:]\n",
    "    return X_train, T_train, X_test, T_test\n",
    "\n",
    "def logistic(x):\n",
    "    # Clip the input values to prevent overflow\n",
    "    clipped_value = 500\n",
    "    clipped_x = np.clip(x, (-1) * clipped_value, clipped_value)\n",
    "    \n",
    "    # Calculate the logistic function on the clipped values\n",
    "    return 1 / (1 + np.exp(-clipped_x))\n",
    "\n",
    "# Negative Log Likelihood - functia J(w)\n",
    "def nll(Y, T):\n",
    "    epsilon = 1e-15\n",
    "    Y = np.clip(Y, epsilon, 1 - epsilon)\n",
    "    return -np.mean(T * np.log(Y) + (1 - T) * np.log(1 - Y))\n",
    "\n",
    "def accuracy(Y, T):\n",
    "    predicted_labels = np.round(Y)\n",
    "    correct_predictions = np.sum(predicted_labels == T)\n",
    "    total_samples = len(T)\n",
    "    return correct_predictions / total_samples\n",
    "\n",
    "# Antrenati modelul logistic (ponderile W), executand epochs_no pasi din algoritmul de gradient descent\n",
    "def train_logistic(X, T, lr=0.01, epochs_no=100):\n",
    "    (N, D) = X.shape\n",
    "    X_hat = np.concatenate([X, np.ones((N, 1))], axis=1)\n",
    "    W = np.random.randn(D + 1)\n",
    "\n",
    "    for epoch in range(epochs_no):\n",
    "        Y = logistic(np.dot(X_hat, W))\n",
    "        gradient = np.dot(X_hat.T, (Y - T))\n",
    "        W -= lr * gradient\n",
    "\n",
    "    return W\n",
    "\n",
    "# Calculati predictia Y a modelului logistic antrenat (ponderile W invatate)\n",
    "def predict_logistic(X, W):\n",
    "    X_hat = np.concatenate([X, np.ones((X.shape[0], 1))], axis=1)\n",
    "    Y = logistic(np.dot(X_hat, W))\n",
    "    return Y\n",
    "\n",
    "def train_logistic_full(X, T, lr=0.01, learning_increase_percent=2.5, epochs_no=1000):\n",
    "    (N, D) = X.shape\n",
    "    X1 = np.concatenate([np.ones((N, 1)), X], axis=1)\n",
    "    W = np.random.randn(D + 1)\n",
    "\n",
    "    X_train, T_train, X_test, T_test = split_dataset(X1, T)\n",
    "    \n",
    "    train_acc, test_acc = [], []\n",
    "    train_nll, test_nll = [], []\n",
    "    W_trace = [W.copy()]\n",
    "\n",
    "    for epoch in range(epochs_no):\n",
    "        Y_train = logistic(np.dot(X_train, W))\n",
    "        gradient = np.dot(X_train.T, (Y_train - T_train))\n",
    "        lr = lr * (1 + learning_increase_percent / 100) # Maresc learning rate-ul pt fiecare epoch\n",
    "        W -= lr * gradient\n",
    "\n",
    "        Y_test = logistic(np.dot(X_test, W))\n",
    "        train_acc.append(accuracy(Y_train, T_train))\n",
    "        test_acc.append(accuracy(Y_test, T_test))\n",
    "        train_nll.append(nll(Y_train, T_train))\n",
    "        test_nll.append(nll(Y_test, T_test))\n",
    "        W_trace.append(W.copy())\n",
    "\n",
    "    return W, train_acc, test_acc, train_nll, test_nll, W_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f93b8d-b934-45e4-9f11-7cae2d9439fa",
   "metadata": {},
   "source": [
    "#### Preprocesarea datelor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a64666-aab9-4bcb-8639-7bc98e289199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split set de date în caracteristici (X) și variabilă țintă (y)\n",
    "X = df.drop('Revenue', axis=1)\n",
    "y = df['Revenue']\n",
    "\n",
    "# Conversia variabilelor categorice în formă numerică\n",
    "label_encoder = LabelEncoder()\n",
    "categorical_columns = ['Month', 'VisitorType', 'Weekend']\n",
    "for column in categorical_columns:\n",
    "    X_train[column] = label_encoder.fit_transform(X_train[column])\n",
    "    X_test[column] = label_encoder.transform(X_test[column])  # Utilizăm aceeași transformare pe setul de test\n",
    "\n",
    "# Normalizarea datelor (Scalare)\n",
    "scalers = {\n",
    "    'MinMaxScaler': MinMaxScaler(),\n",
    "    'StandardScaler': StandardScaler(),\n",
    "    'RobustScaler': RobustScaler()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc47e0a-7947-431a-a17a-ab50f12faae8",
   "metadata": {},
   "source": [
    "#### Antrenare si Testare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55a44a2-ca43-4677-8d08-9535a37e33f2",
   "metadata": {},
   "source": [
    "#### Functie pentru plotting de rezultate dinamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d86761-8dd9-4deb-b96d-377e353a346d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definim o functie ajutatoare pentru plotting\n",
    "def plot_evolution(train_acc, test_acc, train_nll, test_nll, scaler, step_percent=2.5):\n",
    "    # Step_percent = 5 <==> 100 / 5 == 20 X points on the plot\n",
    "    epochs_no = len(train_acc)\n",
    "    step = round(epochs_no * step_percent / 100)\n",
    "    # If step is 0, we will set minimum default step for the plotting\n",
    "    if step == 0:\n",
    "        step = 1\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "\n",
    "    # Plotting accuracy evolution\n",
    "    ax1.plot(range(0, epochs_no, step), train_acc[::step], sns.xkcd_rgb[\"green\"], label=\"Train Accuracy\")\n",
    "    ax1.plot(range(0, epochs_no, step), test_acc[::step], sns.xkcd_rgb[\"red\"], label=\"Test Accuracy\")\n",
    "    ax1.set_ylabel(\"Accuracy\")\n",
    "    ax1.legend(loc='lower right', ncol=1)\n",
    "\n",
    "    # Plotting negative log likelihood evolution\n",
    "    ax2.plot(range(0, epochs_no, step), train_nll[::step], sns.xkcd_rgb[\"green\"], label=\"Train NLL\")\n",
    "    ax2.plot(range(0, epochs_no, step), test_nll[::step], sns.xkcd_rgb[\"red\"], label=\"Test NLL\")\n",
    "    ax2.set_xlabel(\"Epoch\")\n",
    "    ax2.set_ylabel(\"NLL\")\n",
    "    ax2.legend(loc='upper right', ncol=1)\n",
    "\n",
    "    # Adding title with scaler information\n",
    "    plt.suptitle(f'Evolution with Scaler: {scaler}')\n",
    "    \n",
    "    return (ax1, ax2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c7e5ca-ec8a-4c2d-a433-3b96dc00c645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_manual(X, y, lr=0.01, learning_increase_percent=2.5, epochs_no=100, step_percent=1):   \n",
    "    (N, D) = X.shape\n",
    "    # Print information about the training dataset\n",
    "    print(f\"Training dataset size: {N}\")\n",
    "    print(f\"Number of features: {D}\")\n",
    "    \n",
    "    for scaler_name, scaler in scalers.items():\n",
    "        # Scalarea datelor de antrenare\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "        # Antrenarea modelului logistic\n",
    "        W, train_acc, test_acc, train_nll, test_nll, W_trace = train_logistic_full(X_train_scaled, y_train, lr=lr, epochs_no=epochs_no)\n",
    "\n",
    "        # Evaluarea modelului pe setul de testare\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        Y_test = predict_logistic(X_test_scaled, W)\n",
    "        test_accuracy = accuracy(Y_test, y_test)\n",
    "\n",
    "        print(f\"Acuratete folosind {scaler_name}: {test_accuracy}\")\n",
    "\n",
    "        # Vizualizare evolutie\n",
    "        plot_evolution(train_acc, test_acc, train_nll, test_nll, scaler, step_percent)\n",
    "        # Eliberare memorie\n",
    "        del W, train_acc, test_acc, train_nll, test_nll, W_trace\n",
    "\n",
    "# Apelul funcției cu datele specifice\n",
    "EPOCHS_NO = 1000\n",
    "LR = 0.02\n",
    "LEARNING_INCREASE_PERCENT = 0\n",
    "STEP_PERCENT=1.25\n",
    "logistic_regression_manual(X,y, lr=LR, learning_increase_percent=LEARNING_INCREASE_PERCENT, epochs_no=EPOCHS_NO, step_percent=STEP_PERCENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3f8a05-9f60-4b4c-9982-27710c342b44",
   "metadata": {},
   "source": [
    "### 2. Implementare folosind scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa17261a-87fa-4967-9e3d-2bd8218c4536",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for scaler_name, scaler in scalers.items():\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Antrenarea modelului\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluarea modelului\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'Scaler': scaler_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1\n",
    "    })\n",
    "\n",
    "# Afisarea rezultatelor\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63411ad7-2a52-4049-a44a-9a4db117fdd6",
   "metadata": {},
   "source": [
    "## 3.2.2. Arbore de Decizie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7f57b5-ddc8-448e-b6bc-b0057e174a56",
   "metadata": {},
   "source": [
    "### 1. Implementare folosind scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993dca31-93c1-4ba0-a021-5ec0b8f1e4ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97881e82-f007-4a23-bdde-2764465a8810",
   "metadata": {},
   "source": [
    "### 2. Implementare manuală"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92b40e8-fd6c-4e30-b719-d7dc7b1fb8b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
